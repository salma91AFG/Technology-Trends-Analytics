# ğŸ“˜ **Collecte de donnÃ©es via API (Partie 1)**

ğŸ“‚ **Dossier :** `1_api_data_collection/`  
Collecte de donnÃ©es dâ€™emploi via une API Flask simulÃ©e.

Cette section met en place une API locale qui expose des offres dâ€™emploi et sert de premiÃ¨re source de donnÃ©es au pipeline analytique.  
Objectif : reproduire un scÃ©nario rÃ©aliste oÃ¹ une application backend renvoie des donnÃ©es structurÃ©es consommÃ©es par un script Python.

---

## ğŸ” **Vue dâ€™ensemble**

Lâ€™API Flask fonctionne comme une couche dâ€™accÃ¨s aux donnÃ©es basÃ©e sur un fichier JSON dâ€™offres dâ€™emploi.  
Le notebook associÃ© interroge cette API, applique des filtres, agrÃ¨ge les donnÃ©es puis exporte les rÃ©sultats.

Ce module couvre :

- Appels Ã  une API REST
- Utilisation de paramÃ¨tres de requÃªte (`query string`)
- Exploitation dâ€™un JSON issu dâ€™un endpoint
- AgrÃ©gation par localisation et par technologie
- Export vers Excel pour les Ã©tapes suivantes

---

## ğŸ§± **Structure du module**
```
1_api_data_collection/
â”‚
â”œâ”€â”€ API_notebook.ipynb # Collecte, filtrage, agrÃ©gation et export
â”œâ”€â”€ Jobs_API.ipynb # API Flask exÃ©cutÃ©e localement
â”œâ”€â”€ jobs.json # Dataset source consommÃ© par lâ€™API
â””â”€â”€ job-postings.xlsx # RÃ©sultats gÃ©nÃ©rÃ©s aprÃ¨s exÃ©cution
```


---

## âš™ï¸ **API Flask â€“ RÃ´le et fonctionnement**

Cette API agit comme un micro-service permettant de servir et filtrer des offres dâ€™emploi.

Elle :

- charge un fichier JSON local (`jobs.json`)
- expose des endpoints REST
- filtre les donnÃ©es via regex et paramÃ¨tres de requÃªtes (`?Key Skills=Python`, etc.)

### **Endpoints principaux**

| MÃ©thode | Endpoint    | Description                                  |
|---------|-------------|----------------------------------------------|
| GET     | `/data/all` | Renvoie toutes les offres dâ€™emploi           |
| GET     | `/data?...` | Filtre selon un ou plusieurs critÃ¨res        |

### **ParamÃ¨tres supportÃ©s**

- Job Title
- Key Skills
- Location
- Role Category
- Industry
- Role

Exemples de valeurs filtrables :  
`Python`, `C++`, `SQL Server`, `Seattle`, `New York`, etc.

---

## â–¶ï¸ **DÃ©marrer lâ€™API**

1. Ouvrir `Jobs_API.ipynb`
2. ExÃ©cuter toutes les cellules pour lancer le serveur Flask

Lâ€™API devient accessible Ã  lâ€™adresse :

http://127.0.0.1:5000/data


Tant que le notebook est actif, les scripts peuvent interroger l'API via `requests`.

---

## ğŸ§® **Collecte & consolidation**

Le notebook `API_notebook.ipynb` exÃ©cute automatiquement :

- collecte dâ€™annonces par localisation
- collecte dâ€™annonces par technologie
- comptage du nombre dâ€™offres par critÃ¨re
- gÃ©nÃ©ration dâ€™un fichier Excel (`job-postings.xlsx`)

Le fichier contient deux onglets :

| Onglet             | Contenu                                 |
|--------------------|-----------------------------------------|
| `jobs locations`   | Nombre de postes par ville              |
| `langages jobs`    | Nombre de postes par technologie        |

---

## ğŸ“¦ **RÃ©sultats gÃ©nÃ©rÃ©s**

AprÃ¨s exÃ©cution :

âœ”ï¸ `job-postings.xlsx` est crÃ©Ã©  
âœ”ï¸ Les donnÃ©es sont prÃªtes pour analyse, visualisation ou enrichissement

---

## ğŸ§¾ **RÃ´le dans le pipeline global**

Cette Ã©tape reprÃ©sente **la source dâ€™entrÃ©e du projet** :  
Elle fournit un jeu de donnÃ©es propre, contrÃ´lÃ© et reproductible pour les modules suivants :


- Analyse exploratoire (EDA)
- Dashboard final

---
